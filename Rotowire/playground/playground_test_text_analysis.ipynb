{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ubuntu/workspace/XMODE')\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())  \n",
    "import pathlib\n",
    "import ast\n",
    "import csv\n",
    "import itertools\n",
    "from langchain_openai import ChatOpenAI\n",
    "# api_key = os.environ['OPENAI_API_KEY_NEW']\n",
    "api_key = os.environ['RC_API_KEY']\n",
    "base_url = os.environ['RC_API_BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-3.3-70B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Rotowire.tools.text_analysis import get_text_analysis_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.8/envs/m3lx/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` that is available on ChatModels capable of tool calling. You can read more about the method here: <https://python.langchain.com/docs/modules/model_io/chat/structured_output/>.Please follow our extraction use case documentation for more guidelines on how to do information extraction with LLMs. <https://python.langchain.com/docs/use_cases/extraction/>. If you notice other issues, please provide feedback here: <https://github.com/langchain-ai/langchain/discussions/18154>\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context-first: {\"data\": [{\"game_id\": \"0\", \"report_url\": \"reports/0.txt\"}]} <class 'str'>\n",
      "Successfully parsed JSON!\n",
      "Successfully parsed JSON!\n",
      "model.answer The Toronto Raptors\n",
      "model.reasoning The question asks who won the game between the Toronto Raptors and the Philadelphia 76ers. The report states that the host Toronto Raptors defeated the Philadelphia 76ers with a score of 122-95.\n",
      "Considering the information : game_id:0 : The Toronto Raptors\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "import json\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "model = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "llm_local = ChatOpenAI(model=model, base_url=base_url , api_key=api_key, temperature=0)\n",
    "context = [{\"game_id\": \"0\", \"report_url\": \"reports/0.txt\"}]\n",
    "question = \"Who won the game?\"\n",
    "input = {\"question\": question, \"context\": json.dumps({\"data\": context})}\n",
    "model = get_text_analysis_tools(llm, llm_local)\n",
    "result = model.invoke(input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3lx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
